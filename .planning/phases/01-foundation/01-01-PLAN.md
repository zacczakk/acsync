---
phase: 01-foundation
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/types.ts
  - src/errors.ts
  - src/infra/exclusion.ts
  - src/infra/hash.ts
  - src/infra/backup.ts
  - src/infra/atomic-write.ts
  - src/infra/__tests__/exclusion.test.ts
  - src/infra/__tests__/hash.test.ts
  - src/infra/__tests__/backup.test.ts
  - src/infra/__tests__/atomic-write.test.ts
autonomous: true
requirements:
  - DIFF-01
  - FILE-01
  - FILE-02
  - EXCL-01
  - EXCL-02

must_haves:
  truths:
    - "SHA-256 hash of any file returns consistent hex string across runs"
    - "SHA-256 hash of a directory returns consistent hex string regardless of filesystem ordering"
    - "Writing a file creates a timestamped backup of the original first"
    - "Writing a file is atomic — crash during write preserves original"
    - "gsd-* files and directories are excluded from all operations"
    - "Non-canonical items in targets are flagged as warnings, never modified"
  artifacts:
    - path: "src/types.ts"
      provides: "Shared type definitions for Phase 1"
      exports: ["ErrorContext", "ExclusionResult", "SyncConfig"]
    - path: "src/errors.ts"
      provides: "Custom error subclasses with severity (borrowed from vsync ErrorSeverity pattern)"
      exports: ["ErrorSeverity", "SyncError", "AtomicWriteError", "HashError", "BackupError", "ParseError", "shouldRollback"]
    - path: "src/infra/exclusion.ts"
      provides: "Config-driven glob exclusion filter"
      exports: ["createExclusionFilter", "classifyEntry"]
    - path: "src/infra/hash.ts"
      provides: "SHA-256 file and directory hashing"
      exports: ["hashFile", "hashDirectory"]
    - path: "src/infra/backup.ts"
      provides: "Timestamped backup with retention pruning"
      exports: ["backupFile", "pruneBackups"]
    - path: "src/infra/atomic-write.ts"
      provides: "Backup-first atomic file write"
      exports: ["atomicWrite"]
  key_links:
    - from: "src/infra/atomic-write.ts"
      to: "src/infra/backup.ts"
      via: "imports backupFile, calls before write"
      pattern: "import.*backup"
    - from: "src/infra/hash.ts"
      to: "src/infra/exclusion.ts"
      via: "directory hash accepts exclusion predicate"
      pattern: "isExcluded"
    - from: "src/infra/atomic-write.ts"
      to: "src/errors.ts"
      via: "wraps errors in AtomicWriteError"
      pattern: "AtomicWriteError"
    - from: "src/infra/hash.ts"
      to: "src/errors.ts"
      via: "wraps errors in HashError"
      pattern: "HashError"
---

<objective>
Build the core infrastructure utilities: deterministic hashing, atomic file writes with mandatory backup, backup retention, and config-driven exclusion filtering.

Purpose: These are the foundational primitives every subsequent phase depends on. No file in the system is written without atomicWrite. No directory is scanned without the exclusion filter. No drift detection works without deterministic hashing.

Output: 6 source modules + 4 test files covering all Phase 1 requirements (DIFF-01, FILE-01, FILE-02, EXCL-01, EXCL-02).
</objective>

<execution_context>
@/Users/m332023/.config/opencode/get-shit-done/workflows/execute-plan.md
@/Users/m332023/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-foundation/01-RESEARCH.md
@.planning/phases/01-foundation/01-CONTEXT.md
@.planning/codebase/CONVENTIONS.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Types, errors, exclusion filter, and hash module</name>
  <files>
    src/types.ts
    src/errors.ts
    src/infra/exclusion.ts
    src/infra/hash.ts
    src/infra/__tests__/exclusion.test.ts
    src/infra/__tests__/hash.test.ts
  </files>
  <action>
Create the foundational type definitions, error classes, and two stateless infra modules.

**vsync reference files (read before implementing):**
- `~/Repos/oss/vsync/cli/src/utils/errors.ts` — ErrorSeverity enum, SyncError base class with severity + context, named subclasses, `shouldRollback()` helper. Port this pattern.
- `~/Repos/oss/vsync/cli/src/utils/hash.ts` — `hashContent(string)`, `hashBaseItem<T>()` with metadata sort + whitespace normalization. Study the approach but note our divergence below.

**src/types.ts** — Shared types for Phase 1:
- `ErrorContext` interface: `{ operation: string; path: string; cause: Error }` (per research recommendation)
- `ExclusionResult` type: `{ excluded: boolean; reason?: string }` for classifyEntry
- `SyncConfig` interface with `sync.exclusions: string[]` and `sync.backupRetention: number` (per research config.json schema recommendation)
- Export all types

**src/errors.ts** — Borrow vsync's error architecture (`~/Repos/oss/vsync/cli/src/utils/errors.ts`), adapted per CONTEXT.md locked decisions:
- `ErrorSeverity` enum: `WARNING` (log + continue), `RECOVERABLE` (retry/fallback), `FATAL` (rollback + abort) — directly from vsync's pattern. Phase 3 executor needs `shouldRollback()` to decide rollback on error.
- `SyncError extends Error` — base class with `severity: ErrorSeverity` and `context?: Record<string, unknown>`. Like vsync's `SyncError` but also stores `operation` and `path` per CONTEXT.md.
- `AtomicWriteError extends SyncError` — default severity `FATAL`. Stores `operation`, `path`, `cause` from ErrorContext.
- `HashError extends SyncError` — default severity `RECOVERABLE`.
- `BackupError extends SyncError` — default severity `FATAL`.
- `ParseError extends SyncError` — default severity `WARNING` (skip invalid entry, continue — matches vsync's `InvalidConfigError`).
- Each constructor: `constructor(message: string, context: ErrorContext)` → sets `this.name`, `this.operation`, `this.path`, severity, passes `{ cause: context.cause }` to `super()`
- `shouldRollback(error: unknown): boolean` — returns true if error is SyncError with FATAL severity (ported from vsync)
- `isSyncError(error: unknown): error is SyncError` — type guard (ported from vsync)
- `getErrorSeverity(error: unknown): ErrorSeverity` — returns FATAL for non-SyncError (ported from vsync)

**src/infra/exclusion.ts** — Config-driven glob exclusion filter per CONTEXT.md locked decision:
- `createExclusionFilter(patterns: string[]): (name: string) => boolean` — creates `Bun.Glob` for each pattern, returns predicate that tests basename
- `classifyEntry(name: string, canonicalNames: Set<string>, isExcluded: (name: string) => boolean): { status: 'canonical' | 'excluded' | 'non-canonical' }` — returns classification per EXCL-02 (non-canonical items flagged as warning, not touched)
- Match against basename only (not full path) — per research, extract basename with `name.split('/').pop()`
- If `Bun.Glob.match()` has issues with basename matching, fall back to manual check (LOW risk per research)

**src/infra/hash.ts** — SHA-256 content hashing per CONTEXT.md locked decisions:

> **vsync divergence:** vsync hashes *model objects* (`hashBaseItem<T>` — normalizes content via `.trim()`, sorts metadata keys, includes support files). We hash *raw file bytes* instead — simpler, matches CONTEXT.md locked decision ("SHA-256 of file content bytes only — permissions and mtime ignored"). No whitespace normalization, no metadata extraction. The model-level hashing vsync does will not be needed here because our diff engine (Phase 3) compares rendered files, not parsed models.

- `hashFile(filePath: string): Promise<string>` — reads file bytes via `Bun.file(filePath).bytes()`, hashes with `new Bun.CryptoHasher('sha256')`, returns hex digest. Wraps errors in `HashError`.
- `hashDirectory(dirPath: string, isExcluded: (name: string) => boolean): Promise<string>` — scans with `Bun.Glob('**/*')`, skips excluded files entirely, collects `{ relativePath, contentHash }` entries, sorts by relativePath using byte-order comparison `(a < b ? -1 : a > b ? 1 : 0)` (NOT locale-dependent per research pitfall #4), concatenates `relativePath + contentHash` into composite hasher, returns hex digest. Wraps errors in `HashError`.
- Directory hash includes filenames in the hash input (per CONTEXT.md: renaming a file counts as drift)

**Tests (src/infra/__tests__/exclusion.test.ts):**
- `createExclusionFilter(['gsd-*'])` matches `gsd-tools.cjs`, `gsd-plan-checker.md`
- `createExclusionFilter(['gsd-*'])` does NOT match `my-gsd-thing`, `tools.cjs`
- `createExclusionFilter(['*.bak', '.DS_Store'])` matches `foo.bak`, `.DS_Store`
- `classifyEntry` returns 'excluded' for gsd-* items, 'canonical' for known items, 'non-canonical' for unknown items

**Tests (src/infra/__tests__/hash.test.ts):**
- hashFile returns same hex string for same content across calls
- hashFile returns different hex string for different content
- hashDirectory returns same hex string regardless of which order files are processed
- hashDirectory excludes files matching exclusion filter
- hashDirectory changes hash when a file is renamed (filename is part of hash)
- Empty directory returns consistent hash

Follow codebase conventions: camelCase functions, PascalCase types, 2-space indent, single quotes, `node:` prefix for built-in imports.
  </action>
  <verify>
    `bun test src/infra/__tests__/exclusion.test.ts src/infra/__tests__/hash.test.ts` — all tests pass
  </verify>
  <done>
    - Exclusion filter correctly matches glob patterns against basenames
    - classifyEntry distinguishes canonical, excluded, and non-canonical entries
    - hashFile produces deterministic SHA-256 hex for file content
    - hashDirectory produces deterministic hash with sorted file manifest, excluded files skipped, filenames included
    - All custom error subclasses throw with operation context and cause chain
  </done>
</task>

<task type="auto">
  <name>Task 2: Backup with retention and backup-first atomic write</name>
  <files>
    src/infra/backup.ts
    src/infra/atomic-write.ts
    src/infra/__tests__/backup.test.ts
    src/infra/__tests__/atomic-write.test.ts
  </files>
  <action>
Create backup and atomic write modules. Atomic write is the sole file-write entry point — it always backs up first.

**vsync reference files (read before implementing):**
- `~/Repos/oss/vsync/cli/src/utils/atomic-write.ts` — Port this directly. Same temp+fsync+rename pattern. Our version adds backup-before-write and wraps in custom error.
- `~/Repos/oss/vsync/cli/src/core/rollback.ts` — vsync's `createBackup`/`restoreBackup`/`cleanupBackup` lifecycle. Study the interface but note our divergence below.

**src/infra/backup.ts** — Timestamped backup with retention per CONTEXT.md locked decisions:

> **vsync divergence:** vsync uses per-file inline backup (`.vsync-backup-{timestamp}-{filename}` in the *same directory* as the target). We use a *central timestamped directory* (`~/Repos/agents/backups/{timestamp}/`) because this convention already exists in the repo (5 existing backup dirs from manual sync). vsync's approach enables code-driven rollback (`restoreBackup`); ours is for human safety — browse `backups/` to recover. No `restoreBackup` in Phase 1; if needed later, add it then.

- `backupFile(filePath: string, backupDir: string): Promise<void>` — if file exists, copies to `backupDir` preserving just the basename. Creates backupDir with `mkdir({ recursive: true })`. If file doesn't exist, no-op (nothing to back up). Wraps errors in `BackupError`.
- `pruneBackups(backupRoot: string, maxBackups: number): Promise<void>` — reads backupRoot, sorts entries alphabetically (timestamp names sort chronologically), keeps only the most recent `maxBackups` entries, removes the rest with `rm({ recursive: true, force: true })`. Wraps errors in `BackupError`.
- `createBackupDir(backupRoot: string): Promise<string>` — generates timestamp directory name matching existing convention `YYYYMMDDTHHMMSS` (e.g., `20260220T182618`), creates it under backupRoot, returns the full path. This is called once per sync run by the orchestrator.
- Backup root: caller provides path (defaults to `~/Repos/agents/backups/` via config, but the module doesn't hardcode this)
- Default retention: 5 (per research recommendation, Claude's discretion area)
- Use `node:fs/promises` throughout (async — consistent with vsync's async approach)

**src/infra/atomic-write.ts** — Port vsync's `atomicWrite` with backup addition:

Port `~/Repos/oss/vsync/cli/src/utils/atomic-write.ts` nearly verbatim, with two additions: (1) call `backupFile` before writing, (2) wrap errors in `AtomicWriteError`.

- `atomicWrite(targetPath: string, content: string | Uint8Array, backupDir: string): Promise<void>`:
  1. Ensure parent directory exists: `await mkdir(dirname(targetPath), { recursive: true })`
  2. Call `await backupFile(targetPath, backupDir)` — mandatory, no skip option
  3. Create temp file in same directory as target: `.tmp-${randomBytes(8).toString('hex')}` (vsync's naming — use `randomBytes` from `node:crypto`, not pid+timestamp)
  4. Write content via `await writeFile(tmpPath, content)` (use `node:fs/promises` `writeFile`, not `Bun.write`)
  5. Open temp file, `await fileHandle.sync()`, close — forces data to disk (match vsync's async `open` → `.sync()` → `.close()` pattern)
  6. `await rename(tmpPath, targetPath)` — atomic on POSIX
  7. On any error: close file handle if open, clean up temp file (best-effort `unlink`), wrap in `AtomicWriteError`, re-throw
- Temp file MUST be in same directory as target (per research pitfall #1 / vsync does the same)
- Import `{ writeFile, rename, mkdir, unlink, open }` from `node:fs/promises` + `{ randomBytes }` from `node:crypto` — matching vsync's import pattern
- The only differences from vsync's `atomicWrite`: (a) backup call before write, (b) `AtomicWriteError` wrapper, (c) `backupDir` parameter

**Tests (src/infra/__tests__/backup.test.ts):**
- backupFile copies file to backup directory
- backupFile is no-op when source file doesn't exist
- backupFile creates backup directory if it doesn't exist
- pruneBackups keeps only maxBackups entries, removes oldest
- pruneBackups is no-op when fewer than maxBackups entries exist
- createBackupDir returns path with correct timestamp format

**Tests (src/infra/__tests__/atomic-write.test.ts):**
- atomicWrite creates file with correct content
- atomicWrite creates backup of existing file before overwriting
- atomicWrite cleans up temp file on write failure
- atomicWrite creates parent directories if missing
- After successful atomicWrite, no .tmp files remain
- atomicWrite wraps errors in AtomicWriteError with context

Use real filesystem for tests (per AGENTS.md: no mocks). Create temp directories with `mkdtempSync` for test isolation, clean up in afterEach.

Follow codebase conventions: camelCase functions, 2-space indent, single quotes, `node:` prefix for built-in imports.
  </action>
  <verify>
    `bun test src/infra/__tests__/backup.test.ts src/infra/__tests__/atomic-write.test.ts` — all tests pass
  </verify>
  <done>
    - backupFile copies target to timestamped backup directory before any modification
    - pruneBackups keeps only N most recent backups, removes oldest
    - atomicWrite always backs up first, writes via temp+fsync+rename pattern
    - No temp files left behind on success or failure
    - All errors wrapped in BackupError or AtomicWriteError with operation context
  </done>
</task>

</tasks>

<verification>
Run full Phase 1 Plan 01 test suite:
```bash
bun test src/infra/__tests__/
```

All tests must pass. Verify:
- No external dependencies needed (all Bun built-ins + node:fs)
- No `any` or `as` in TypeScript
- Custom error subclasses have correct name, operation, path, cause properties
- Hash is deterministic across multiple runs
- Atomic write + backup work together (write creates backup, then writes atomically)
</verification>

<success_criteria>
- All 4 test files pass with `bun test`
- hashFile returns consistent SHA-256 hex for same content
- hashDirectory produces deterministic hash with exclusion filtering
- atomicWrite always creates backup before writing
- atomicWrite is crash-safe (temp → fsync → rename pattern)
- Exclusion filter matches gsd-* patterns and classifies non-canonical items
- All errors are wrapped custom subclasses with operation context
</success_criteria>

<output>
After completion, create `.planning/phases/01-foundation/01-01-SUMMARY.md`
</output>
